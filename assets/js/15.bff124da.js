(window.webpackJsonp=window.webpackJsonp||[]).push([[15],{341:function(t,s,a){"use strict";a.r(s);var e=a(7),n=Object(e.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"安装postgresql"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#安装postgresql"}},[t._v("#")]),t._v(" 安装postgresql")]),t._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token function"}},[t._v("sudo")]),t._v(" yum "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("install")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-y")]),t._v(" https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm\n"),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("sudo")]),t._v(" yum update\n"),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("sudo")]),t._v(" yum "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("install")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-y")]),t._v(" postgresql15-server\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 初始化 postgresql")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("sudo")]),t._v(" /usr/pgsql-15/bin/postgresql-15-setup initdb\n"),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("sudo")]),t._v(" systemctl "),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("enable")]),t._v(" postgresql-15\n"),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("sudo")]),t._v(" systemctl start postgresql-15\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 检查服务")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("sudo")]),t._v(" systemctl status postgresql-15\n")])])]),s("table",[s("thead",[s("tr",[s("th",[t._v("术语")]),t._v(" "),s("th",[t._v("解释")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[s("code",[t._v("tsvector")])]),t._v(" "),s("td",[t._v("待检索的文档")])]),t._v(" "),s("tr",[s("td",[s("code",[t._v("tsquery")])]),t._v(" "),s("td",[t._v("用于检索的查询，包含了一系列的搜索词(search term)和操作符")])])])]),t._v(" "),s("h2",{attrs:{id:"如何使用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#如何使用"}},[t._v("#")]),t._v(" 如何使用")]),t._v(" "),s("h3",{attrs:{id:"准备数据"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#准备数据"}},[t._v("#")]),t._v(" 准备数据")]),t._v(" "),s("div",{staticClass:"language-sql extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 建表")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("table")]),t._v(" t_docs "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    id "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("primary")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("key")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    title "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("varchar")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("256")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    content "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("varchar")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4096")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("insert")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("into")]),t._v(" t_docs "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Learing PG Full Text Search'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'PG support Full Text search. Full Text Searching (or just text search) provides the capability to identify natural-language documents that satisfy a query, and optionally to sort them by relevance to the query. The most common type of search is to find all documents containing given query terms and return them in order of their similarity to the query. Notions of query and similarity are very flexible and depend on the specific application. The simplest search considers query as a set of words and similarity as the frequency of query words in the document.'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("insert")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("into")]),t._v(" t_docs "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Learing PG Index'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Although indexes in PostgreSQL do not need maintenance or tuning, it is still important to check which indexes are actually used by the real-life query workload. Examining index usage for an individual query is done with the EXPLAIN command; its application for this purpose is illustrated in Section 14.1. It is also possible to gather overall statistics about index usage in a running server, as described in Section 28.2.'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("insert")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("into")]),t._v(" t_docs "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'The SQL Language'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'This part describes the use of the SQL language in PostgreSQL. We start with describing the general syntax of SQL, then explain how to create the structures to hold data, how to populate the database, and how to query it. The middle part lists the available data types and functions for use in SQL commands. The rest treats several aspects that are important for tuning a database for optimal performance.'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("insert")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("into")]),t._v(" t_docs "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'What Is PostgreSQL'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'PostgreSQL is an object-relational database management system (ORDBMS) based on POSTGRES, Version 4.2, developed at the University of California at Berkeley Computer Science Department. POSTGRES pioneered many concepts that only became available in some commercial database systems much later.'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("insert")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("into")]),t._v(" t_docs "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'A Brief History of PostgreSQL'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'The object-relational database management system now known as PostgreSQL is derived from the POSTGRES package written at the University of California at Berkeley. With over two decades of development behind it, PostgreSQL is now the most advanced open-source database available anywhere.'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("p",[t._v("全文搜索可以不依赖索引，如：")]),t._v(" "),s("div",{staticClass:"language-sql extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 关键字 `open-source` ")]),t._v("\nfence"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# select id,title from t_docs where to_tsvector(content) @@ to_tsquery('open-source');")]),t._v("\n id "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("             title\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("----+-------------------------------")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" A Brief History "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("of")]),t._v(" PostgreSQL\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("row")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 关键字 `postgres`")]),t._v("\nfence"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# select id,title from t_docs where to_tsvector(content) @@ to_tsquery('postgres');")]),t._v("\n id "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("             title\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("----+-------------------------------")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" What "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("Is")]),t._v(" PostgreSQL\n  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" A Brief History "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("of")]),t._v(" PostgreSQL\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("rows")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 关键字 `postgresql`")]),t._v("\nfence"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# select id,title from t_docs where to_tsvector(content) @@ to_tsquery('postgresql');")]),t._v("\n id "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("             title\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("----+-------------------------------")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" Learing PG "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("Index")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" The "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SQL")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("Language")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" What "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("Is")]),t._v(" PostgreSQL\n  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" A Brief History "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("of")]),t._v(" PostgreSQL\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("rows")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 两个关键字，从多列中检索")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 下例中如果不从title中检索，则 id 为 2 的记录不会返回")]),t._v("\nfence"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# select id,title from t_docs where to_tsvector(content || ' ' || title) @@ to_tsquery('postgres | pg');")]),t._v("\n id "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("             title\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("----+-------------------------------")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" Learing PG "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("Full")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("Text")]),t._v(" Search\n  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" Learing PG "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("Index")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" What "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("Is")]),t._v(" PostgreSQL\n  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" A Brief History "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("of")]),t._v(" PostgreSQL\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("rows")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("由此可知，在postgresql的默认配置下：")]),t._v(" "),s("ul",[s("li",[t._v("全文检索时关键字的大小写不影响搜索结果")]),t._v(" "),s("li",[t._v("在默认词典中，"),s("code",[t._v("postgres")]),t._v(" 和 "),s("code",[t._v("postgresql")]),t._v(" 不是近义词，也没有派生关系")])]),t._v(" "),s("p",[t._v("使用索引可以加速查询，全文搜索支持两种索引：")]),t._v(" "),s("ul",[s("li",[t._v("GIN")]),t._v(" "),s("li",[t._v("GIST")])]),t._v(" "),s("p",[t._v("创建 "),s("code",[t._v("GIN")]),t._v(" 索引")]),t._v(" "),s("blockquote",[s("p",[t._v("索引列必须指定config name(即下例中的 "),s("code",[t._v("english")]),t._v(")，如果不指定，则会使用 "),s("a",{attrs:{href:"https://www.postgresql.org/docs/current/runtime-config-client.html#GUC-DEFAULT-TEXT-SEARCH-CONFIG",target:"_blank",rel:"noopener noreferrer"}},[t._v("default_text_search_config"),s("OutboundLink")],1),t._v(" 构建索引，若后续该配置被修改，则之前已经建立的索引将无法使用。")])]),t._v(" "),s("div",{staticClass:"language-sql extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 复制 10000 行数据")]),t._v("\nfence"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# insert into t_docs select t*5+d.id as id, d.title, d.content from generate_series(1, 2000) as t, t_docs d;")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INSERT")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10000")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 创建索引")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("index")]),t._v(" i_docs__content "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("on")]),t._v(" t_docs "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("using")]),t._v(" GIN "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("to_tsvector"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'english'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" content"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 检查，已经可以击中索引")]),t._v("\nfence"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# explain select id,title from t_docs where to_tsvector('english', content) @@ to_tsquery('postgres');")]),t._v("\n                                                QUERY "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("PLAN")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("----------------------------------------------------------------------------------------------------------")]),t._v("\n Bitmap Heap Scan "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("on")]),t._v(" t_docs  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cost"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12.64")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v(".188")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v(".55")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("rows")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),t._v(" width"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("520")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   Recheck Cond: "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("to_tsvector"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'english'")]),t._v("::regconfig"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("content"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("::"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("text")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" @@ to_tsquery"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'postgres'")]),t._v("::"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("text")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("  Bitmap "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("Index")]),t._v(" Scan "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("on")]),t._v(" i_docs__content  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cost"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.00")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v(".12")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v(".63")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("rows")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),t._v(" width"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("Index")]),t._v(" Cond: "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("to_tsvector"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'english'")]),t._v("::regconfig"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("content"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("::"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("text")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" @@ to_tsquery"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'postgres'")]),t._v("::"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("text")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("rows")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("div",{staticClass:"language-sql extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 试验可见，创建索引之后，速度明显提升, 从 723 毫秒提升到 1 毫秒")]),t._v("\nfence"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# \\timing")]),t._v("\nTiming "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("is")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("on")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\nfence"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# select count(1) from t_docs where to_tsvector('english', content) @@ to_tsquery('postgres');")]),t._v("\n count\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-------")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4002")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("row")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("Time")]),t._v(": "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("723.538")]),t._v(" ms\nfence"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# create index i_docs__content on t_docs using GIN (to_tsvector('english', content));")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INDEX")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("Time")]),t._v(": "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("911.129")]),t._v(" ms\nfence"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# select count(1) from t_docs where to_tsvector('english', content) @@ to_tsquery('postgres');")]),t._v("\n count\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-------")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4002")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("row")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("Time")]),t._v(": "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.329")]),t._v(" ms\n")])])]),s("p",[t._v("索引可以建立在多个列上")]),t._v(" "),s("div",{staticClass:"language-sql extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[t._v("fence"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# create index i_docs__title_content on t_docs using GIN (to_tsvector('english', title || ' ' || content));")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INDEX")]),t._v("\n")])])]),s("p",[t._v("我们还可以将 "),s("code",[t._v("to_tsvector")]),t._v(" 的输出单独保存一列，保持其可以随着源数据保持更新。在其之上创建索引，以用于检索。")]),t._v(" "),s("div",{staticClass:"language-sql extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 新增索引列")]),t._v("\nfence"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# alter table t_docs add column search_title_content_index_col tsvector generated always as (to_tsvector('english', coalesce(title, '') || ' ' || coalesce(content, ''))) stored;")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ALTER")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 检查索引列数据")]),t._v("\nfence"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# select search_title_content_index_col from t_docs limit 1;")]),t._v("\n                                                                                                                                                                                                                                          sear\nch_title_content_index_col\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("----------------------")]),t._v("\n "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'applic'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("80")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'capabl'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'common'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("43")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'consid'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("84")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'contain'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("52")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'depend'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("76")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'document'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("26")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("51")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'find'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("49")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'flexibl'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("74")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'frequenc'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("95")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'full'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'given'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("53")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'identifi'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("22")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'languag'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("25")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'lear'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'natur'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("24")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'natural-languag'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("23")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'notion'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("67")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\noption'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'order'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("60")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'pg'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'provid'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'queri'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("40")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("54")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("66")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("69")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("85")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("97")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'relev'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("37")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'return'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("57")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'satisfi'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("28")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'search'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("13")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("17")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("46")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("83")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'set'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("88")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'similar'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("63")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("71")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("92")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'simplest'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("82")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'sort'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("34")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'specif'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("79")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'support'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'term'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("55")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'text'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("16")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\ntype'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("44")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'word'")]),t._v(":"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("90")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("98")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("row")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 在索引列上创建索引")]),t._v("\nfence"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# create index i_docs__title_content_index_col on t_docs using GIN(search_title_content_index_col);")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INDEX")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 检验是否击中索引")]),t._v("\nfence"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# explain select count(1) from t_docs where search_title_content_index_col @@  to_tsquery('postgres');")]),t._v("\n                                              QUERY "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("PLAN")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("------------------------------------------------------------------------------------------------------")]),t._v("\n Aggregate  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cost"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("195.90")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v(".195")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v(".91")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("rows")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" width"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("  Bitmap Heap Scan "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("on")]),t._v(" t_docs  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cost"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12.64")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v(".195")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v(".77")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("rows")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),t._v(" width"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         Recheck Cond: "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("search_title_content_index_col @@ to_tsquery"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'postgres'")]),t._v("::"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("text")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("  Bitmap "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("Index")]),t._v(" Scan "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("on")]),t._v(" i_docs__title_content_index_col  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cost"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.00")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v(".12")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v(".63")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("rows")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),t._v(" width"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n               "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("Index")]),t._v(" Cond: "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("search_title_content_index_col @@ to_tsquery"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'postgres'")]),t._v("::"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("text")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("rows")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 检索数据")]),t._v("\nfence"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# select count(1) from t_docs where search_title_content_index_col @@  to_tsquery('postgres');")]),t._v("\n count\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-------")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4002")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=n.exports}}]);